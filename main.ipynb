{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load librarys\n",
    "\n",
    "Procondition is that you have installed the with anaconda the packages listed in the NeuNe_notebook.yaml file.\n",
    "\n",
    "```bash\n",
    "conda env create -f NeuNe_notebook.yaml\n",
    "```\n",
    "\n",
    "```bash\n",
    "conda activate NeuNe_notebook\n",
    "```\n",
    "\n",
    "```bash\n",
    "conda env update --file NeuNe_notebook.yaml  --prune\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repository hosts a Convolutional Neural Network (CNN) model for brain tumor detection. Leveraging the dataset available on Kaggle [1], our classifier aims to accurately identify the presence of tumors in brain MRI images. Contributions to medical image analysis and early tumor detection are central to this project.\n",
    "\n",
    "ðŸŒ Sources\n",
    "https://www.kaggle.com/datasets/jakeshbohaju/brain-tumor - Brain Tumor Dataset\n",
    "\n",
    "Point out, possibly, related work or problems in the literature/internet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "# Load the images and create neural network model with TensorFlow \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data and associate Labes\n",
    "\n",
    "### Extract Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the dataset\n",
    "z = zipfile.ZipFile('archive.zip')\n",
    "\n",
    "# Extract all the contents of zip file in current directory to a new folder named 'data'\n",
    "z.extractall('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Tumor and Non-Tumor\n",
    "\n",
    "This step is important to separate the data into two classes, tumor and non-tumor. This is important to train the model to distinguish between the two classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_csv = pd.read_csv('data/Brain Tumor.csv')\n",
    "label_csv.head()\n",
    "\n",
    "image_folder = 'data/Brain Tumor/Brain Tumor'\n",
    "\n",
    "# Save all the images to a folder named tumor and non_tumor\n",
    "tumor_folder = 'data/labeled/tumor'\n",
    "non_tumor_folder = 'data/labeled/non_tumor'\n",
    "\n",
    "# Create the folders\n",
    "os.makedirs(tumor_folder, exist_ok=True)\n",
    "os.makedirs(non_tumor_folder, exist_ok=True)\n",
    "\n",
    "# Copy the images to the folders\n",
    "for index, row in label_csv.iterrows():\n",
    "    image_path = os.path.join(image_folder, row['Image']+ '.jpg')\n",
    "    if row['Class'] == 1:\n",
    "        shutil.copy(image_path, tumor_folder)\n",
    "    else:\n",
    "        shutil.copy(image_path, non_tumor_folder)\n",
    "\n",
    "# Check the number of images in each folder\n",
    "print('Number of images in tumor folder:', len(os.listdir(tumor_folder)))\n",
    "print('Number of images in non_tumor folder:', len(os.listdir(non_tumor_folder)))\n",
    "\n",
    "# Display a few images from each folder\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(mpimg.imread(os.path.join(tumor_folder, os.listdir(tumor_folder)[i])))\n",
    "    plt.title('Tumor')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(mpimg.imread(os.path.join(non_tumor_folder, os.listdir(non_tumor_folder)[i])))\n",
    "    plt.title('Non Tumor')\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Brain Tumor Image Dataset\n",
    "\n",
    "#### Dataset Overview\n",
    "\n",
    "The dataset consists of brain MRI images categorized into two classes: \"Tumor\" and \"Non-Tumor.\" The images are stored in separate folders based on their class labels. Here's a summary of the data distribution:\n",
    "\n",
    "- **Number of images in the \"Tumor\" folder:** 1683\n",
    "- **Number of images in the \"Non-Tumor\" folder:** 2079\n",
    "\n",
    "#### Data Visualization\n",
    "\n",
    "To understand the dataset better, we visualized a sample of images from both classes.\n",
    "These images provide a visual representation of the differences between tumor and non-tumor MRI scans. Tumor images typically show abnormal growths and irregular patterns, whereas non-tumor images exhibit normal brain structures without any noticeable anomalies.\n",
    "\n",
    "#### Relevant Data Features\n",
    "\n",
    "For the project, the key features to focus on are the visual characteristics of the MRI images that distinguish tumor from non-tumor cases. These features include:\n",
    "\n",
    "- **Shape and Size:** Tumors usually have irregular shapes and varying sizes compared to normal brain tissue.\n",
    "- **Texture:** Tumor regions often have different texture patterns compared to non-tumor regions.\n",
    "- **Intensity:** The intensity values (brightness and contrast) in tumor regions can differ significantly from those in healthy brain tissue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data with tensorflow as pipline\n",
    "\n",
    "In this step we will load the data into the tensorflow pipeline. This is important to load the data in a way that the model can be trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building data pipeline\n",
    "data = tf.keras.utils.image_dataset_from_directory('data/labeled')\n",
    "\n",
    "# create a data iterator\n",
    "data_iterator = data.as_numpy_iterator()\n",
    "\n",
    "# creat a batch with 32 images\n",
    "batch = data_iterator.next()\n",
    "\n",
    "# images represented as numpy arrays\n",
    "batch[0].shape\n",
    "\n",
    "# plot the batch to see which class belongs to which image\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    # set the title of the image with tumor or non_tumor\n",
    "    ax[idx].title.set_text('Tumor' if batch[1][idx] == 1 else 'Non Tumor')\n",
    "    ax[idx].axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Data Scaling\n",
    "\n",
    "In this step the data is normalized and scaled. In addition the data is converted to a grayscale image in order to have less features and to be able to train the model faster, as well as to reduce the risk of overfitting.\n",
    "This can be done, as the data is anyway only black and white images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data pipline on the fly \n",
    "data_norm = data.map(lambda x, y: (x/255, y))\n",
    "\n",
    "# preprocess the data to gray scale\n",
    "data_gray = data.map(lambda x, y: (tf.image.rgb_to_grayscale(x), y))\n",
    "\n",
    "# create a scaled data iterator\n",
    "scaled_interator = data_gray.as_numpy_iterator()\n",
    "scaled_batch = scaled_interator.next()\n",
    "scaled_batch[0].min()\n",
    "\n",
    "# display the batch\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20, 20))\n",
    "for idx, img in enumerate(scaled_batch[0][:4]):\n",
    "    ax[idx].imshow(img, cmap='gray')\n",
    "    ax[idx].title.set_text('Tumor' if batch[1][idx] == 1 else 'Non Tumor')\n",
    "    ax[idx].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data\n",
    "\n",
    "In this step the data is split into training, validation and test data. This is important to be able to evaluate the model on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide the size of the train, validation and test datasets\n",
    "print(len(data_gray))\n",
    "train_size = int(len(data_gray)*.7)\n",
    "val_size = int(len(data_gray)*.2)+1\n",
    "test_size = int(len(data_gray)*.1)+1\n",
    "\n",
    "# calculate the total number of batches\n",
    "total_batches = train_size + val_size + test_size\n",
    "\n",
    "print(\"Total number of batches:\", total_batches)\n",
    "# this number is not exact because the last batch may not have 32 images\n",
    "print(\"Total number of images (not exact):\", total_batches*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train, validation and test\n",
    "train = data_gray.take(train_size)\n",
    "val = data_gray.skip(train_size).take(val_size)\n",
    "test = data_gray.skip(train_size+val_size).take(test_size)\n",
    "\n",
    "print(f\"Train: {len(train)} batches, Validation: {len(val)} batches, Test: {len(test)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augementation\n",
    "\n",
    "This step is important to increase the amount of data and to reduce the risk of overfitting. It was one of the most challenging steps, as we had to find the right parameters to increase the data and to not overfit the model, but also not make the data too different from the original data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation only for training\n",
    "train_data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(height_factor=(-0.1, 0.1), width_factor=None),\n",
    "    tf.keras.layers.RandomBrightness(0.1, value_range=(0, 255))\n",
    "])\n",
    "\n",
    "# Apply augmentation to the training dataset\n",
    "train_augmented = train.map(lambda x, y: (train_data_augmentation(x, training=True), y))\n",
    "\n",
    "# Define the percentage of augmented data\n",
    "augmented_data_percentage = 0.4\n",
    "\n",
    "# Calculate the number of augmented images\n",
    "augmented_data_size = int(len(train) * augmented_data_percentage*32)\n",
    "\n",
    "print('Number of augmented images:', augmented_data_size)\n",
    "\n",
    "# combine the augmented data with the original data\n",
    "train_combined = train.concatenate(train_augmented.take(augmented_data_size)).shuffle(1000)\n",
    "\n",
    "print('Number of images in the combined dataset:', len(train_combined) * 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display some picture of the train_combined dataset\n",
    "fig, ax = plt.subplots(ncols=10, figsize=(20, 20))\n",
    "for idx, img in enumerate(train_combined.take(10)):\n",
    "    ax[idx].imshow(img[0][0], cmap='gray')\n",
    "    ax[idx].title.set_text('Tumor' if img[1][0] == 1 else 'Non Tumor')\n",
    "    ax[idx].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation and Compilation\n",
    "\n",
    "In this step the model is created and compiled. Important was to have in the last layer only one neuron, with a sigmoid acitvation, as we have a binary classification problem. The other parameters were chosen on try and error basis. Except for the input shape, which was chosen to be the size of the images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural network model which loads the images and classifies them as tumor or non-tumor and the csv file with values like standard deviation, mean, etc.\n",
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(256, 256, 1)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[Precision(), Recall(), BinaryAccuracy(), 'accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_combined, validation_data=val, epochs=10, callbacks=[EarlyStopping(patience=3)])\n",
    "\n",
    "\n",
    "# Plot the accuracy and loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the accuracy and loss log scale\n",
    "# This is usefull because the loss is very high in the beginning and then it decreases\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (log scale)')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (log scale)')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot the precision and recall\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['precision'], label='precision')\n",
    "plt.plot(history.history['val_precision'], label='val_precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['recall'], label='recall')\n",
    "plt.plot(history.history['val_recall'], label='val_recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Performance\n",
    "\n",
    "In this step the model is evaluated on the test data. This is important to see how well the model performs on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Messures used for classification problems, precision, recall and accuracy. \n",
    "# Establish instance of precision, recall and accuracy\n",
    "pre =  Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()\n",
    "\n",
    "# Iterate over the test dataset\n",
    "for batch in test.as_numpy_iterator():\n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "\n",
    "    # Reshape yhat if necessary to match the dimensions of y\n",
    "    if yhat.shape[-1] == 1:\n",
    "        yhat = tf.squeeze(yhat, axis=-1)  # Squeeze the last dimension\n",
    "\n",
    "    # Update metric states\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)  # Here, we correctly use BinaryAccuracy\n",
    "\n",
    "print('Precision:', pre.result().numpy())\n",
    "print('Recall:', re.result().numpy())\n",
    "print('Accuracy:', acc.result().numpy())\n",
    "\n",
    "# Calculate the AUC\n",
    "auc = roc_auc_score(y, yhat)\n",
    "print('AUC:', auc)\n",
    "\n",
    "# Calculate the F1 score\n",
    "f1 = f1_score(y, yhat > 0.5)\n",
    "print('F1:', f1)\n",
    "\n",
    "# Print the results after processing all batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Collect all true labels and predicted labels\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "\n",
    "# Iterate over the test dataset again to collect true and predicted labels\n",
    "for batch in test.as_numpy_iterator():\n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "\n",
    "    # Reshape yhat if necessary to match the dimensions of y\n",
    "    if yhat.shape[-1] == 1:\n",
    "        yhat = tf.squeeze(yhat, axis=-1)  # Squeeze the last dimension\n",
    "\n",
    "    # Collect the true and predicted labels for confusion matrix\n",
    "    all_y_true.extend(y)\n",
    "    all_y_pred.extend(yhat)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_y_true = np.array(all_y_true)\n",
    "all_y_pred = np.array(all_y_pred)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(all_y_true, all_y_pred > 0.5)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted No Tumor', 'Predicted Tumor'], yticklabels=['True No Tumor', 'True Tumor'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Extract and print detailed counts with descriptions\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f'True Negatives (No Tumor): {tn}')\n",
    "print(f'False Positives (No Tumor but shows Tumor): {fp}')\n",
    "print(f'False Negatives (Tumor but shows No Tumor): {fn}')\n",
    "print(f'True Positives (Tumor): {tp}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on Random Images\n",
    "\n",
    "In this section the model evaluates some random images from the data set. This is just for try and error and has no big impact on the evaluation of the model, as the most images are already seen by the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test dataset and display the images\n",
    "tumor_folder = 'data/labeled/tumor'\n",
    "non_tumor_folder = 'data/labeled/non_tumor'\n",
    "\n",
    "# Make 6 predictions on the test dataset without tumor\n",
    "non_tumor_folder_random_images = os.listdir(non_tumor_folder)\n",
    "\n",
    "# select 6 random images\n",
    "random.shuffle(non_tumor_folder_random_images)\n",
    "\n",
    "for i, image in enumerate(non_tumor_folder_random_images[:6]):\n",
    "    img = tf.keras.preprocessing.image.load_img(os.path.join(non_tumor_folder, image), target_size=(256, 256), color_mode='grayscale')\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create a batch\n",
    "\n",
    "    prediction = model.predict(img_array)\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title('Non Tumor' if prediction < 0.5 else 'Tumor')\n",
    "    plt.axis('off')\n",
    "    plt.suptitle('Predictions on Non Tumor Images')\n",
    "plt.show()\n",
    "\n",
    "tumor_folder_random_images = os.listdir(tumor_folder)\n",
    "\n",
    "# select 6 random images\n",
    "random.shuffle(tumor_folder_random_images)\n",
    "\n",
    "# Make 6 predictions on the test dataset with tumor\n",
    "for i, image in enumerate(tumor_folder_random_images[:6]):\n",
    "    img = tf.keras.preprocessing.image.load_img(os.path.join(tumor_folder, image), target_size=(256, 256), color_mode='grayscale')\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create a batch\n",
    "\n",
    "    prediction = model.predict(img_array)\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title('Non Tumor' if prediction < 0.5 else 'Tumor')\n",
    "    plt.axis('off')\n",
    "    plt.suptitle('Predictions on Tumor Images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "\n",
    "In this step the model is saved. This is important to be able to use the model later on for predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model folder\n",
    "os.makedirs('model', exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model.save(os.path.join('model', 'brain_tumor_classifier.keras'))\n",
    "\n",
    "# save the model in the h5 format which is outdated but still used by some applications\n",
    "model.save('model/brain_tumor_classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showcase the Model\n",
    "\n",
    "Now you can use the model to predict the class of any brain MRI image.\n",
    "\n",
    "Create for that a new virtual environment and install the required libraries:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Then you can start the streamlit app with the following command:\n",
    "\n",
    "```bash\n",
    "streamlit run dashboard.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "The next steps would be to improve the model by using a more complex model. In addition, the data augmentation could be improved by using more parameters and more data. Also, the model could be trained on more data, as the data set was quite small. Also the model could use additional data, such as the mean, variance or standard deviation of the pictures. Other interesting parameters would be to use patient data, such as Age and Sex.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".cv_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
